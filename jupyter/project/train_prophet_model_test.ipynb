{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WACS prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:39:44,099 - [DEBUG] - matplotlib.pyplot - (pyplot.py).switch_backend(301) - Loaded backend module://matplotlib_inline.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from prophet import Prophet, serialize\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import mlflow\n",
    "import sys\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG,\n",
    "                    format=f\"%(asctime)s - [%(levelname)s] - %(name)s - (%(filename)s).%(funcName)s(%(lineno)d) - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "ARTIFACT_PATH = \"model\"\n",
    "tracking_server_uri = \"http://138.68.70.41:5000\"  # set to your server URI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mlflow.set_tracking_uri(tracking_server_uri)\n",
    "except:\n",
    "    logger.debbug(\"\"\"Couldn't connect to remote MLFLOW tracking server\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_params(pr_model):\n",
    "    return {attr: getattr(pr_model, attr) for attr in serialize.SIMPLE_ATTRIBUTES}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df, settings):\n",
    "\n",
    "    # Init prophet model\n",
    "\n",
    "    m = Prophet(\n",
    "        growth=settings[\"growth\"],\n",
    "        seasonality_mode=settings[\"seasonality_mode\"],\n",
    "        changepoint_prior_scale=settings['changepoint_prior_scale'],\n",
    "        seasonality_prior_scale=settings['seasonality_prior_scale'],\n",
    "        daily_seasonality=settings['daily_seasonality'],\n",
    "        weekly_seasonality=settings['weekly_seasonality'],\n",
    "        yearly_seasonality=settings['yearly_seasonality']\n",
    "    )\n",
    "\n",
    "    for season in settings['seasonality']:\n",
    "        m.add_seasonality(\n",
    "            name=season['name'],\n",
    "            period=season['period'],\n",
    "            fourier_order=season['fourier_order']\n",
    "        )\n",
    "\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        model = m.fit(df)  \n",
    "        params = extract_params(model)\n",
    "\n",
    "        metric_keys = [\"mse\", \"rmse\", \"mae\", \"mape\", \"mdape\", \"smape\", \"coverage\"]\n",
    "        \n",
    "        cross_validation_params = settings.get('cross_validation')\n",
    "        cross_validation_enable = settings.get('cross_validation_enabled')\n",
    "\n",
    "#       if cross_validation_params and cross_validation_enable:\n",
    "        metrics_raw = cross_validation(\n",
    "                model=model,\n",
    "                horizon=cross_validation_params.get('horizon'),  # \"365\",\n",
    "                period=cross_validation_params.get('period'),  # \"180\",\n",
    "                initial=cross_validation_params.get('initial'),  # \"710\",\n",
    "                parallel=cross_validation_params.get(\n",
    "                    'parallel'),  # \"threads\",\n",
    "                disable_tqdm=cross_validation_params.get(\n",
    "                    'disable_tqdm')\n",
    "        )\n",
    "\n",
    "        cv_metrics = performance_metrics(metrics_raw)\n",
    "        metrics = {k: cv_metrics[k].mean() for k in metric_keys}\n",
    "\n",
    "        logger.debug(\n",
    "            f\"Logged Metrics: \\n{json.dumps(metrics, indent=2)}\")\n",
    "        logger.debug(\n",
    "            f\"Logged Params: \\n{json.dumps(params, indent=2)}\")\n",
    "\n",
    "        mlflow.prophet.log_model(model, artifact_path=ARTIFACT_PATH)\n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model_uri = mlflow.get_artifact_uri(ARTIFACT_PATH)\n",
    "\n",
    "        logger.debug(f\"Model artifact logged to: {model_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model settings\n",
    "settings = {\n",
    "        \"growth\": \"linear\", \n",
    "        \"seasonality_mode\": \"multiplicative\", \n",
    "        \"changepoint_prior_scale\": 30,\n",
    "        \"seasonality_prior_scale\": 35,\n",
    "        \"interval_width\": 0.98,\n",
    "        \"daily_seasonality\": \"auto\",\n",
    "        \"weekly_seasonality\": \"auto\",\n",
    "        \"yearly_seasonality\": False, \n",
    "        \"seasonality\": [{\"name\": \"hour\",\"period\": 0.417, \"fourier_order\": 5}], \n",
    "        \"cross_validation\":{\n",
    "            \"horizon\":\"12 hours\", \n",
    "            \"period\":\"2 hours\", \n",
    "            \"initial\":\"24 hours\",\n",
    "            \"parallel\":\"threads\",\n",
    "            \"disable_tqdm\":True\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>2022-02-10 12:25</td>\n",
       "      <td>78.472451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>2022-02-10 12:26</td>\n",
       "      <td>78.555164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ds          y\n",
       "2878  2022-02-10 12:25  78.472451\n",
       "2879  2022-02-10 12:26  78.555164"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOURCE_DATA = (\n",
    "    \"https://raw.githubusercontent.com/rkrikbaev/model-training/master/jupyter/project/fp_archives.csv\"\n",
    ")\n",
    "# SOURCE_DATA = (\n",
    "#     \"https://raw.githubusercontent.com/facebook/prophet/master/examples/example_retail_sales.csv\"\n",
    "# )\n",
    "\n",
    "df = pd.read_csv(SOURCE_DATA, sep=';')\n",
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:15,513 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:43:15,539 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"POST /api/2.0/mlflow/runs/create HTTP/1.1\" 200 750\n",
      "2022-08-04 07:43:15,561 - [INFO] - prophet - (forecaster.py).parse_seasonality_args(921) - Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
      "2022-08-04 07:43:15,566 - [INFO] - prophet - (forecaster.py).parse_seasonality_args(921) - Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
      "2022-08-04 07:43:15,611 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/pm7r1huu.json\n",
      "2022-08-04 07:43:15,640 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/j8xekz0h.json\n",
      "2022-08-04 07:43:15,643 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:15,646 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:15,647 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=9456', 'data', 'file=/tmp/tmp0qlloh2o/pm7r1huu.json', 'init=/tmp/tmp0qlloh2o/j8xekz0h.json', 'output', 'file=/tmp/tmp6juf619a/prophet_model-20220804074315.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:15 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:15,651 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,187 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n",
      "2022-08-04 07:43:23,228 - [INFO] - prophet - (diagnostics.py).generate_cutoffs(55) - Making 6 forecasts with cutoffs between 2022-02-09 14:26:00 and 2022-02-10 00:26:00\n",
      "2022-08-04 07:43:23,229 - [INFO] - prophet - (diagnostics.py).cross_validation(192) - Applying in parallel with <concurrent.futures.thread.ThreadPoolExecutor object at 0x7f68735d1250>\n",
      "2022-08-04 07:43:23,380 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/fkfucc3p.json\n",
      "2022-08-04 07:43:23,405 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/l76gpvxt.json\n",
      "2022-08-04 07:43:23,424 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:23,460 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:23,463 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=91216', 'data', 'file=/tmp/tmp0qlloh2o/fkfucc3p.json', 'init=/tmp/tmp0qlloh2o/l76gpvxt.json', 'output', 'file=/tmp/tmpcjz7e4g0/prophet_model-20220804074323.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,445 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/lfnhd3g6.json\n",
      "2022-08-04 07:43:23,468 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n",
      "2022-08-04 07:43:23,527 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/zpgw_b8w.json\n",
      "2022-08-04 07:43:23,543 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/vzymoj2o.json\n",
      "2022-08-04 07:43:23,543 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/sbqusy5z.json\n",
      "2022-08-04 07:43:23,566 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/k5f4f4vm.json\n",
      "2022-08-04 07:43:23,588 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:23,605 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:23,609 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=3257', 'data', 'file=/tmp/tmp0qlloh2o/lfnhd3g6.json', 'init=/tmp/tmp0qlloh2o/k5f4f4vm.json', 'output', 'file=/tmp/tmpnec2vdc5/prophet_model-20220804074323.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,569 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/23ycb6o2.json\n",
      "2022-08-04 07:43:23,610 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n",
      "2022-08-04 07:43:23,647 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/l6kjqqp0.json\n",
      "2022-08-04 07:43:23,670 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:23,670 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/bi6yqcqj.json\n",
      "2022-08-04 07:43:23,674 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:23,675 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:23,676 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=96946', 'data', 'file=/tmp/tmp0qlloh2o/zpgw_b8w.json', 'init=/tmp/tmp0qlloh2o/bi6yqcqj.json', 'output', 'file=/tmp/tmp_wtzqg1v/prophet_model-20220804074323.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,672 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:23,678 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=59090', 'data', 'file=/tmp/tmp0qlloh2o/sbqusy5z.json', 'init=/tmp/tmp0qlloh2o/l6kjqqp0.json', 'output', 'file=/tmp/tmp_agaka9s/prophet_model-20220804074323.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,670 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/0u4cp2on.json\n",
      "2022-08-04 07:43:23,680 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:23,681 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:23,682 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=42365', 'data', 'file=/tmp/tmp0qlloh2o/vzymoj2o.json', 'init=/tmp/tmp0qlloh2o/0u4cp2on.json', 'output', 'file=/tmp/tmpn2d_dgwr/prophet_model-20220804074323.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,678 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n",
      "2022-08-04 07:43:23,676 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n",
      "2022-08-04 07:43:23,685 - [DEBUG] - cmdstanpy - (utils.py).__init__(1448) - input tempfile: /tmp/tmp0qlloh2o/ptgdtau7.json\n",
      "2022-08-04 07:43:23,683 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n",
      "2022-08-04 07:43:23,721 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1552) - idx 0\n",
      "2022-08-04 07:43:23,736 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1553) - running CmdStan, num_threads: None\n",
      "2022-08-04 07:43:23,751 - [DEBUG] - cmdstanpy - (model.py)._run_cmdstan(1565) - CmdStan args: ['/usr/local/lib/python3.8/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=96324', 'data', 'file=/tmp/tmp0qlloh2o/23ycb6o2.json', 'init=/tmp/tmp0qlloh2o/ptgdtau7.json', 'output', 'file=/tmp/tmpwv63uj7y/prophet_model-20220804074323.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:23 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:23,752 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1568) - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:33,468 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:36,736 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:38,952 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:40,335 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:41,317 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:43:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-04 07:43:42,187 - [INFO] - cmdstanpy - (model.py)._run_cmdstan(1608) - Chain [1] done processing\n",
      "2022-08-04 07:44:11,035 - [DEBUG] - __main__ - (4248716220.py).train(48) - Logged Metrics: \n",
      "{\n",
      "  \"mse\": 9351.185930939262,\n",
      "  \"rmse\": 90.25531279098,\n",
      "  \"mae\": 65.86038899234282,\n",
      "  \"mape\": 4.481336152927343,\n",
      "  \"mdape\": 3.495724374685615,\n",
      "  \"smape\": 1.3049227672608839,\n",
      "  \"coverage\": 0.8897306397306398\n",
      "}\n",
      "2022-08-04 07:44:11,037 - [DEBUG] - __main__ - (4248716220.py).train(50) - Logged Params: \n",
      "{\n",
      "  \"growth\": \"linear\",\n",
      "  \"n_changepoints\": 25,\n",
      "  \"specified_changepoints\": false,\n",
      "  \"changepoint_range\": 0.8,\n",
      "  \"yearly_seasonality\": false,\n",
      "  \"weekly_seasonality\": \"auto\",\n",
      "  \"daily_seasonality\": \"auto\",\n",
      "  \"seasonality_mode\": \"multiplicative\",\n",
      "  \"seasonality_prior_scale\": 35.0,\n",
      "  \"changepoint_prior_scale\": 30.0,\n",
      "  \"holidays_prior_scale\": 10.0,\n",
      "  \"mcmc_samples\": 0,\n",
      "  \"interval_width\": 0.8,\n",
      "  \"uncertainty_samples\": 1000,\n",
      "  \"y_scale\": 85.88370658790792,\n",
      "  \"logistic_floor\": false,\n",
      "  \"country_holidays\": null,\n",
      "  \"component_modes\": {\n",
      "    \"additive\": [\n",
      "      \"additive_terms\",\n",
      "      \"extra_regressors_additive\"\n",
      "    ],\n",
      "    \"multiplicative\": [\n",
      "      \"hour\",\n",
      "      \"multiplicative_terms\",\n",
      "      \"extra_regressors_multiplicative\",\n",
      "      \"holidays\"\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "2022-08-04 07:44:11,067 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:44:11,083 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"GET /api/2.0/mlflow/runs/get?run_uuid=dc93ac05a78b480d96265d3adcc729f6&run_id=dc93ac05a78b480d96265d3adcc729f6 HTTP/1.1\" 200 750\n",
      "2022-08-04 07:44:11,092 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:44:11,109 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"POST /api/2.0/mlflow/runs/log-model HTTP/1.1\" 200 2\n",
      "2022-08-04 07:44:11,118 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:44:11,153 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2022-08-04 07:44:11,160 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:44:11,186 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"POST /api/2.0/mlflow/runs/log-batch HTTP/1.1\" 200 2\n",
      "2022-08-04 07:44:11,197 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:44:11,221 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"GET /api/2.0/mlflow/runs/get?run_uuid=dc93ac05a78b480d96265d3adcc729f6&run_id=dc93ac05a78b480d96265d3adcc729f6 HTTP/1.1\" 200 4025\n",
      "2022-08-04 07:44:11,230 - [DEBUG] - __main__ - (4248716220.py).train(59) - Model artifact logged to: file:///root/model-training/mlruns/0/dc93ac05a78b480d96265d3adcc729f6/artifacts/model\n",
      "2022-08-04 07:44:11,241 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._new_conn(228) - Starting new HTTP connection (1): 138.68.70.41:5000\n",
      "2022-08-04 07:44:11,267 - [DEBUG] - urllib3.connectionpool - (connectionpool.py)._make_request(456) - http://138.68.70.41:5000 \"POST /api/2.0/mlflow/runs/update HTTP/1.1\" 200 399\n"
     ]
    }
   ],
   "source": [
    "train(df, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
